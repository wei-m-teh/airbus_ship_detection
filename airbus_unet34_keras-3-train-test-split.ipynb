{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 20\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT= 4\n",
    "VALIDATION_COUNT_PCT = 0.1\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 500\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc; gc.enable() # memory is tight\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '/mnt/fsx/airbus_data/'\n",
    "train_image_dir = os.path.join(ship_dir, 'train_small')\n",
    "from skimage.morphology import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543 masks found\n",
      "957\n",
      "                                             ImageId  \\\n",
      "0  000155de5_cc7a0ba3-e660-472b-b8f2-ec2fe1174400...   \n",
      "1  000194a2d_9abc3b11-d82c-4fbf-9014-b4d11787d6d5...   \n",
      "2  000194a2d_9abc3b11-d82c-4fbf-9014-b4d11787d6d5...   \n",
      "3  000194a2d_9abc3b11-d82c-4fbf-9014-b4d11787d6d5...   \n",
      "4  000194a2d_9abc3b11-d82c-4fbf-9014-b4d11787d6d5...   \n",
      "\n",
      "                                       EncodedPixels  \n",
      "0  186376 1 187141 4 187907 7 188672 10 189438 13...  \n",
      "1  309689 4 310455 6 311222 8 311989 9 312755 11 ...  \n",
      "2  357323 1 358089 3 358855 6 359620 9 360388 10 ...  \n",
      "3  190702 1 191469 6 192237 6 193005 7 193772 7 1...  \n",
      "4  451292 1 452058 4 452824 6 453590 9 454358 9 4...  \n"
     ]
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                 'train_ship_segmentations_small.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "print(masks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>001bcf222_a4fbdc00-5568-47df-b0a7-5958a30865cd...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>007b25c03_be94c3b5-b370-4692-936e-ed65c9df17ba...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0038cbe45_9a294ad1-10fb-4760-a015-08d667cdb188...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>001234638_043d4e70-c478-4fd0-9eed-6ef2b182da42...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>002c78530_042be6a5-509d-4311-8f7b-ccd62ded9d21...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ImageId  ships  has_ship  \\\n",
       "245  001bcf222_a4fbdc00-5568-47df-b0a7-5958a30865cd...      1       1.0   \n",
       "932  007b25c03_be94c3b5-b370-4692-936e-ed65c9df17ba...      4       1.0   \n",
       "475  0038cbe45_9a294ad1-10fb-4760-a015-08d667cdb188...      1       1.0   \n",
       "165  001234638_043d4e70-c478-4fd0-9eed-6ef2b182da42...      1       1.0   \n",
       "372  002c78530_042be6a5-509d-4311-8f7b-ccd62ded9d21...      2       1.0   \n",
       "\n",
       "    has_ship_vec  \n",
       "245        [1.0]  \n",
       "932        [1.0]  \n",
       "475        [1.0]  \n",
       "165        [1.0]  \n",
       "372        [1.0]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(masks, unique_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x + 1) // 2).clip(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grouped_ship_count\n",
       "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: ships, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_train_df = train_df.groupby('grouped_ship_count')\n",
    "grouped_train_df['ships'].hist(bins=np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ships_for_validation(in_df, total, valid_pct):\n",
    "    group_cnt = in_df['ImageId'].count()\n",
    "    frac = int(total * valid_pct * group_cnt // total)\n",
    "    print(\"group cnt: {}, fraction: {}\".format(group_cnt, frac))\n",
    "    return in_df.sample(frac, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group cnt: 921, fraction: 92\n",
      "group cnt: 443, fraction: 44\n",
      "group cnt: 123, fraction: 12\n",
      "group cnt: 56, fraction: 5\n"
     ]
    }
   ],
   "source": [
    "total = train_df['ImageId'].count()\n",
    "valid_pct = 0.1\n",
    "valid_df = grouped_train_df.apply(sample_ships_for_validation, total, valid_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df = train_df[~train_df['ImageId'].isin(valid_df['ImageId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 1218, validation sample size: 153\n"
     ]
    }
   ],
   "source": [
    "print(\"training samples: {}, validation sample size: {}\".format(all_train_df['ImageId'].count(), valid_df['ImageId'].count()))\n",
    "training_samples = all_train_df['ImageId'].count()\n",
    "validation_samples = valid_df['ImageId'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (4, 768, 768, 3) 0.0 1.0\n",
      "y (4, 768, 768, 1) 0 1\n"
     ]
    }
   ],
   "source": [
    "train_gen = make_image_gen(all_train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (153, 768, 768, 3) 0.0 1.0\n",
      "y (153, 768, 768, 1) 0 1\n"
     ]
    }
   ],
   "source": [
    "valid_gen = make_image_gen(valid_df, validation_samples) # pull all validation samples\n",
    "valid_x, valid_y = next(valid_gen)\n",
    "print('x', valid_x.shape, valid_x.min(), valid_x.max())\n",
    "print('y', valid_y.shape, valid_y.min(), valid_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to CSV and \n",
    "masks[masks['ImageId'].isin(all_train_df['ImageId'])].to_csv('{}/train_ship_segmentations_train.csv'.format(ship_dir), index=False)\n",
    "masks[masks['ImageId'].isin(valid_df['ImageId'])].to_csv('{}/train_ship_segmentations_valid.csv'.format(ship_dir), index=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
