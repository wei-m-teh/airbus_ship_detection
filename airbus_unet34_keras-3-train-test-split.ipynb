{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 20\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT= 4\n",
    "VALIDATION_COUNT_PCT= 0.001\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 500\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc; gc.enable() # memory is tight\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '/mnt/fsx/airbus_data/deep_learning_v2'\n",
    "train_image_dir = os.path.join(ship_dir, 'augmented')\n",
    "from skimage.morphology import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3616871 masks found\n",
      "2033172\n",
      "                                             ImageId  \\\n",
      "0  000155de5_f6248d89-63c8-4b6b-bf48-bc76a1113538...   \n",
      "1  000194a2d_8d25adc5-48c0-4d7b-97ec-7d40cfc084a3...   \n",
      "2  000194a2d_8d25adc5-48c0-4d7b-97ec-7d40cfc084a3...   \n",
      "3  000194a2d_8d25adc5-48c0-4d7b-97ec-7d40cfc084a3...   \n",
      "4  000194a2d_8d25adc5-48c0-4d7b-97ec-7d40cfc084a3...   \n",
      "\n",
      "                                       EncodedPixels  \n",
      "0  287464 2 288232 4 288999 7 289767 9 290535 12 ...  \n",
      "1  93243 2 94008 6 94774 8 95542 8 96310 9 97079 ...  \n",
      "2  370690 2 371457 4 371462 2 372226 6 372993 6 3...  \n",
      "3  189490 4 190255 7 191021 10 191790 9 192558 9 ...  \n",
      "4  244036 2 244800 7 245567 8 246333 10 247098 14...  \n"
     ]
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                 'train_ship_segmentations_v2_aug.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "print(masks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>623328</th>\n",
       "      <td>4ebdd7c55_dff7cb14-d674-44cb-8a9e-bf67c80310a8...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988242</th>\n",
       "      <td>7c35d33fc_682ce343-e7f0-47fd-a4d1-620be58b44d4...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051959</th>\n",
       "      <td>8482ef4d6_ffb66e5d-0545-40aa-a6ac-25813bd50a05...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104300</th>\n",
       "      <td>8b50707f3_cab2c8c0-aa46-4774-81ed-2ef586afe912...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912301</th>\n",
       "      <td>72d0c8d62_85e699d6-7a83-461c-88c5-8abb5ed01e14...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ImageId  ships  has_ship  \\\n",
       "623328   4ebdd7c55_dff7cb14-d674-44cb-8a9e-bf67c80310a8...      1       1.0   \n",
       "988242   7c35d33fc_682ce343-e7f0-47fd-a4d1-620be58b44d4...      1       1.0   \n",
       "1051959  8482ef4d6_ffb66e5d-0545-40aa-a6ac-25813bd50a05...      3       1.0   \n",
       "1104300  8b50707f3_cab2c8c0-aa46-4774-81ed-2ef586afe912...      1       1.0   \n",
       "912301   72d0c8d62_85e699d6-7a83-461c-88c5-8abb5ed01e14...      2       1.0   \n",
       "\n",
       "        has_ship_vec  \n",
       "623328         [1.0]  \n",
       "988242         [1.0]  \n",
       "1051959        [1.0]  \n",
       "1104300        [1.0]  \n",
       "912301         [1.0]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(masks, unique_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x + 1) // 2).clip(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grouped_ship_count\n",
       "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "5    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "6    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "7    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: ships, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD6CAYAAACPpxFEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXiUlEQVR4nO3db4zd1X3n8fe3dvnbEBsoI9d2a3djkRBoFBiB20jVKO7CQKKYB0ECdYNhvbKKHJo2VMW0D9wmi0S0TUnoEjZW7NrsIgjrZoVVTFwLuKpWCg7/Uowx1COD8AQnBGxcJiihzn73wT0T3xnuzOAz9r3X4/dLupp7v79zfufMYWY+/v25l8hMJEk6Wr/S7QlIkk5MBogkqYoBIkmqYoBIkqoYIJKkKgaIJKnKlAESERsi4vWIeL7Ntj+LiIyIc8vriIi7ImIoIp6LiItb2q6IiD3lsaKlfklE7Cx97oqIKPWzI2J7ab89IuZONYYkqXNmv482G4H/DtzbWoyIhcB/BF5tKV8JLCmPy4B7gMsi4mxgLdAPJPB0RGzJzIOlzSrgCWArMAg8AqwBHs3MOyJiTXl960RjTPVNnHvuublo0aL38e2+109/+lPOPPPMqr4zkesxlutxhGsx1kxYj6effvqNzPz1thszc8oHsAh4flxtM/Ax4BXg3FL7JnBdS5uXgHnAdcA3W+rfLLV5wIst9V+2G+1bns8DXppsjKm+h0suuSRrPf7449V9ZyLXYyzX4wjXYqyZsB7AUznB39WqayAR8Rngh5n5L+M2zQf2tbweLrXJ6sNt6gB9mbkfoHw9b4oxJEkd9H5OYY0REWcAfwlc3m5zm1pW1CedwvvtExGraJ4eo6+vj0ajMcWu2xsZGanuOxO5HmO5Hke4FmPN9PU46gAB/gOwGPiXcr17AfBMRFxK82hgYUvbBcBrpT4wrt4o9QVt2gP8OCLmZeb+iJgHvF7qE43xHpm5DlgH0N/fnwMDA+2aTanRaFDbdyZyPcZyPY5wLcaa6etx1KewMnNnZp6XmYsycxHNP+gXZ+aPgC3A9eVOqaXAoXL6aRtweUTMLXdTXQ5sK9vejoil5e6r64GHylBbgNG7tVaMq7cbQ5LUQVMegUTE/TSPHs6NiGFgbWaun6D5VuAqYAh4B7gRIDMPRMSXgSdLuy9l5oHy/Caad3qdTvPuq0dK/Q7gwYhYSfNOr2smG0OS1FlTBkhmXjfF9kUtzxNYPUG7DcCGNvWngAvb1N8ElrWpTziGJKlzfCe6JKmKASJJqmKASJKq1NzGqy5ZtObhbk8BgI2DJ/ZHM0g6NjwCkSRVMUAkSVUMEElSFQNEklTFAJEkVTFAJElVDBBJUhUDRJJUxQCRJFUxQCRJVQwQSVIVA0SSVMUAkSRVMUAkSVUMEElSFQNEklTFAJEkVTFAJElVpgyQiNgQEa9HxPMttf8WES9GxHMR8X8iYk7LttsiYigiXoqIK1rqg6U2FBFrWuqLI2JHROyJiG9HxCmlfmp5PVS2L5pqDElS57yfI5CNwOC42nbgwsz8HeBfgdsAIuIC4Frgo6XPNyJiVkTMAu4GrgQuAK4rbQG+AtyZmUuAg8DKUl8JHMzMDwF3lnYTjnGU37ckaZqmDJDM/GfgwLjaP2Xm4fLyCWBBeb4ceCAzf56ZLwNDwKXlMZSZezPzXeABYHlEBPBJYHPpvwm4umVfm8rzzcCy0n6iMSRJHXQsroH8Z+CR8nw+sK9l23CpTVQ/B3irJYxG62P2VbYfKu0n2pckqYNmT6dzRPwlcBi4b7TUplnSPqhykvaT7WuyPuPntwpYBdDX10ej0WjXbEojIyPVfY+lWy46PHWjDuiV9egVrscRrsVYM309qgMkIlYAnwaWZeboH/BhYGFLswXAa+V5u/obwJyImF2OMlrbj+5rOCJmAx+keSptsjHGyMx1wDqA/v7+HBgYOPpvFGg0GtT2PZZuWPNwt6cAwMbBM3tiPXpFr/x89ALXYqyZvh5Vp7AiYhC4FfhMZr7TsmkLcG25g2oxsAT4PvAksKTccXUKzYvgW0rwPA58tvRfATzUsq8V5flngcdK+4nGkCR10JRHIBFxPzAAnBsRw8BamnddnQpsb17X5onM/KPM3BURDwIv0Dy1tTozf1H283lgGzAL2JCZu8oQtwIPRMR/BZ4F1pf6euB/RsQQzSOPawEmG0OS1DlTBkhmXtemvL5NbbT97cDtbepbga1t6ntpcxdVZv4MuOZoxpAkdY7vRJckVTFAJElVDBBJUhUDRJJUxQCRJFUxQCRJVQwQSVIVA0SSVMUAkSRVMUAkSVUMEElSFQNEklTFAJEkVTFAJElVDBBJUhUDRJJUxQCRJFUxQCRJVQwQSVIVA0SSVMUAkSRVMUAkSVWmDJCI2BARr0fE8y21syNie0TsKV/nlnpExF0RMRQRz0XExS19VpT2eyJiRUv9kojYWfrcFRFRO4YkqXPezxHIRmBwXG0N8GhmLgEeLa8BrgSWlMcq4B5ohgGwFrgMuBRYOxoIpc2qln6DNWNIkjprygDJzH8GDowrLwc2leebgKtb6vdm0xPAnIiYB1wBbM/MA5l5ENgODJZtZ2Xm9zIzgXvH7etoxpAkddDsyn59mbkfIDP3R8R5pT4f2NfSbrjUJqsPt6nXjLF//CQjYhXNoxT6+vpoNBpH910WIyMj1X2PpVsuOtztKQC9sx69wvU4wrUYa6avR22ATCTa1LKiXjPGe4uZ64B1AP39/TkwMDDFrttrNBrU9j2WbljzcLenAMDGwTN7Yj16Ra/8fPQC12Ksmb4etXdh/Xj0tFH5+nqpDwMLW9otAF6bor6gTb1mDElSB9UGyBZg9E6qFcBDLfXry51SS4FD5TTUNuDyiJhbLp5fDmwr296OiKXl7qvrx+3raMaQJHXQlKewIuJ+YAA4NyKGad5NdQfwYESsBF4FrinNtwJXAUPAO8CNAJl5ICK+DDxZ2n0pM0cvzN9E806v04FHyoOjHUOS1FlTBkhmXjfBpmVt2iaweoL9bAA2tKk/BVzYpv7m0Y4hSeoc34kuSapigEiSqhggkqQqBogkqYoBIkmqYoBIkqoYIJKkKgaIJKmKASJJqmKASJKqGCCSpCoGiCSpigEiSapigEiSqhggkqQqBogkqYoBIkmqYoBIkqoYIJKkKgaIJKmKASJJqjKtAImIP42IXRHxfETcHxGnRcTiiNgREXsi4tsRcUppe2p5PVS2L2rZz22l/lJEXNFSHyy1oYhY01JvO4YkqXOqAyQi5gN/DPRn5oXALOBa4CvAnZm5BDgIrCxdVgIHM/NDwJ2lHRFxQen3UWAQ+EZEzIqIWcDdwJXABcB1pS2TjCFJ6pDpnsKaDZweEbOBM4D9wCeBzWX7JuDq8nx5eU3ZviwiotQfyMyfZ+bLwBBwaXkMZebezHwXeABYXvpMNIYkqUOqAyQzfwj8DfAqzeA4BDwNvJWZh0uzYWB+eT4f2Ff6Hi7tz2mtj+szUf2cScaQJHXI7NqOETGX5tHDYuAt4H/TPN00Xo52mWDbRPV24TZZ+3ZzXAWsAujr66PRaLRrNqWRkZHqvsfSLRcdnrpRB/TKevQK1+MI12Ksmb4e1QEC/AHwcmb+BCAivgP8HjAnImaXI4QFwGul/TCwEBgup7w+CBxoqY9q7dOu/sYkY4yRmeuAdQD9/f05MDBQ9Y02Gg1q+x5LN6x5uNtTAGDj4Jk9sR69old+PnqBazHWTF+P6VwDeRVYGhFnlOsSy4AXgMeBz5Y2K4CHyvMt5TVl+2OZmaV+bblLazGwBPg+8CSwpNxxdQrNC+1bSp+JxpAkdch0roHsoHkh+xlgZ9nXOuBW4IsRMUTzesX60mU9cE6pfxFYU/azC3iQZvh8F1idmb8oRxefB7YBu4EHS1smGUOS1CHTOYVFZq4F1o4r76V5B9X4tj8DrplgP7cDt7epbwW2tqm3HUOS1Dm+E12SVMUAkSRVMUAkSVUMEElSFQNEklTFAJEkVTFAJElVDBBJUhUDRJJUZVrvRNfJaecPD/XEBzu+csenuj0F6aTmEYgkqYoBIkmqYoBIkqoYIJKkKgaIJKmKASJJqmKASJKqGCCSpCoGiCSpigEiSapigEiSqhggkqQq0wqQiJgTEZsj4sWI2B0RvxsRZ0fE9ojYU77OLW0jIu6KiKGIeC4iLm7Zz4rSfk9ErGipXxIRO0ufuyIiSr3tGJKkzpnuEcjXge9m5oeBjwG7gTXAo5m5BHi0vAa4ElhSHquAe6AZBsBa4DLgUmBtSyDcU9qO9hss9YnGkCR1SHWARMRZwO8D6wEy893MfAtYDmwqzTYBV5fny4F7s+kJYE5EzAOuALZn5oHMPAhsBwbLtrMy83uZmcC94/bVbgxJUodM5wjkt4GfAH8fEc9GxLci4kygLzP3A5Sv55X284F9Lf2HS22y+nCbOpOMIUnqkOn8D6VmAxcDN2fmjoj4OpOfSoo2tayov28RsYrmKTD6+vpoNBpH0/2XRkZGqvseS7dcdLjbUwCg7/TemEsv/DeB3vn56AWuxVgzfT2mEyDDwHBm7iivN9MMkB9HxLzM3F9OQ73e0n5hS/8FwGulPjCu3ij1BW3aM8kYY2TmOmAdQH9/fw4MDLRrNqVGo0Ft32OpF/4vgNAMj6/u7P7/zPKVPxzo9hSA3vn56AWuxVgzfT2qT2Fl5o+AfRFxfiktA14AtgCjd1KtAB4qz7cA15e7sZYCh8rpp23A5RExt1w8vxzYVra9HRFLy91X14/bV7sxJEkdMt1/Rt4M3BcRpwB7gRtphtKDEbESeBW4prTdClwFDAHvlLZk5oGI+DLwZGn3pcw8UJ7fBGwETgceKQ+AOyYYQ5LUIdMKkMz8AdDfZtOyNm0TWD3BfjYAG9rUnwIubFN/s90YkqTO8Z3okqQqBogkqYoBIkmqYoBIkqoYIJKkKgaIJKmKASJJqmKASJKqGCCSpCoGiCSpigEiSapigEiSqhggkqQqBogkqYoBIkmqYoBIkqoYIJKkKgaIJKmKASJJqmKASJKqGCCSpCoGiCSpyrQDJCJmRcSzEfGP5fXiiNgREXsi4tsRcUqpn1peD5Xti1r2cVupvxQRV7TUB0ttKCLWtNTbjiFJ6pxjcQTyBWB3y+uvAHdm5hLgILCy1FcCBzPzQ8CdpR0RcQFwLfBRYBD4RgmlWcDdwJXABcB1pe1kY0iSOmRaARIRC4BPAd8qrwP4JLC5NNkEXF2eLy+vKduXlfbLgQcy8+eZ+TIwBFxaHkOZuTcz3wUeAJZPMYYkqUNmT7P/14A/Bz5QXp8DvJWZh8vrYWB+eT4f2AeQmYcj4lBpPx94omWfrX32jatfNsUYY0TEKmAVQF9fH41G4+i/Q2BkZKS677F0y0WHp27UAX2n98ZcGvd/rdtTAGDkAx/qiZ+PXtArvyu9YqavR3WARMSngdcz8+mIGBgtt2maU2ybqN7u6Giy9u8tZq4D1gH09/fnwMBAu2ZTajQa1PY9lm5Y83C3pwA0w+OrO6f7b4/pe+W0td2eAgCNgYd64uejF/TK70qvmOnrMZ2/Ap8APhMRVwGnAWfRPCKZExGzyxHCAuC10n4YWAgMR8Rs4IPAgZb6qNY+7epvTDKGJKlDqq+BZOZtmbkgMxfRvAj+WGb+IfA48NnSbAXwUHm+pbymbH8sM7PUry13aS0GlgDfB54ElpQ7rk4pY2wpfSYaQ5LUIcfjfSC3Al+MiCGa1yvWl/p64JxS/yKwBiAzdwEPAi8A3wVWZ+YvytHF54FtNO/yerC0nWwMSVKHHJMT2ZnZABrl+V6ad1CNb/Mz4JoJ+t8O3N6mvhXY2qbedgxJUuf4TnRJUhUDRJJUxQCRJFUxQCRJVQwQSVIVA0SSVMUAkSRVMUAkSVUMEElSFQNEklTFAJEkVTFAJElVuv9/BZJOdPt/AH+1vNuzgL861O0Z6CTjEYgkqYoBIkmqYoBIkqoYIJKkKgaIJKmKASJJqmKASJKqGCCSpCrVARIRCyPi8YjYHRG7IuILpX52RGyPiD3l69xSj4i4KyKGIuK5iLi4ZV8rSvs9EbGipX5JROwsfe6KiJhsDElS50znCOQwcEtmfgRYCqyOiAuANcCjmbkEeLS8BrgSWFIeq4B7oBkGwFrgMuBSYG1LINxT2o72Gyz1icaQJHVIdYBk5v7MfKY8fxvYDcwHlgObSrNNwNXl+XLg3mx6ApgTEfOAK4DtmXkgMw8C24HBsu2szPxeZiZw77h9tRtDktQhx+QaSEQsAj4O7AD6MnM/NEMGOK80mw/sa+k2XGqT1Yfb1JlkDElSh0z7wxQj4teAfwD+JDP/rVymaNu0TS0r6kczt1U0T4HR19dHo9E4mu6/NDIyUt33WLrlosPdngIAfaf3xlwav/LX3Z4CACOn/gaN83tgLj3wM9orvyu9Yqavx7QCJCJ+lWZ43JeZ3ynlH0fEvMzcX05DvV7qw8DClu4LgNdKfWBcvVHqC9q0n2yMMTJzHbAOoL+/PwcGBto1m1Kj0aC277F0w5qHuz0FoBkeX93Z/Q9yfuW0td2eAgCN8/+agZe6P5eL3v3Nbk+Bv/utv+uJ35Ve0St/O46X6dyFFcB6YHdm/m3Lpi3A6J1UK4CHWurXl7uxlgKHyumnbcDlETG3XDy/HNhWtr0dEUvLWNeP21e7MSRJHTKdf0Z+AvgcsDMiflBqfwHcATwYESuBV4FryratwFXAEPAOcCNAZh6IiC8DT5Z2X8rMA+X5TcBG4HTgkfJgkjEkSR1SHSCZ+X9pf50CYFmb9gmsnmBfG4ANbepPARe2qb/ZbgxJUuf4TnRJUhUDRJJUxQCRJFUxQCRJVbp/M7+kGeOFN1/g5k03d3sa7Fyxs9tTOCl4BCJJqmKASJKqeApL0oyz+8Mf6fYUmv7HPd2ewXHlEYgkqYpHIJJ0nPxs1y52/9FN3Z4GH3lx93HZr0cgkqQqBogkqYoBIkmq4jUQSTpO3v7Ab/LYwN3dngbH6540j0AkSVUMEElSFQNEklTFAJEkVTFAJElVDBBJUhUDRJJUxQCRJFU5oQMkIgYj4qWIGIqINd2ejySdTE7YAImIWcDdwJXABcB1EXFBd2clSSePEzZAgEuBoczcm5nvAg8Ay7s8J0k6aZzIATIf2NfyerjUJEkdEJnZ7TlUiYhrgCsy87+U158DLs3Mm1varAJWlZfnAy9VDncu8MY0pjvTuB5juR5HuBZjzYT1+K3M/PV2G07kT+MdBha2vF4AvNbaIDPXAeumO1BEPJWZ/dPdz0zheozlehzhWow109fjRD6F9SSwJCIWR8QpwLXAli7PSZJOGifsEUhmHo6IzwPbgFnAhszc1eVpSdJJ44QNEIDM3Aps7cBQ0z4NNsO4HmO5Hke4FmPN6PU4YS+iS5K660S+BiJJ6iIDZAp+XMoREbEwIh6PiN0RsSsivtDtOXVbRMyKiGcj4h+7PZdui4g5EbE5Il4sPyO/2+05dUtE/Gn5HXk+Iu6PiNO6PafjwQCZhB+X8h6HgVsy8yPAUmD1Sb4eAF8Adnd7Ej3i68B3M/PDwMc4SdclIuYDfwz0Z+aFNG/yuba7szo+DJDJ+XEpLTJzf2Y+U56/TfMPxEn77v+IWAB8CvhWt+fSbRFxFvD7wHqAzHw3M9/q7qy6ajZwekTMBs5g3HvUZgoDZHJ+XMoEImIR8HFgR3dn0lVfA/4c+H/dnkgP+G3gJ8Dfl1N634qIM7s9qW7IzB8CfwO8CuwHDmXmP3V3VseHATK5aFM76W9bi4hfA/4B+JPM/Lduz6cbIuLTwOuZ+XS359IjZgMXA/dk5seBnwIn5TXDiJhL80zFYuA3gDMj4j91d1bHhwEyuSk/LuVkExG/SjM87svM73R7Pl30CeAzEfEKzVObn4yI/9XdKXXVMDCcmaNHpJtpBsrJ6A+AlzPzJ5n578B3gN/r8pyOCwNkcn5cSouICJrnuHdn5t92ez7dlJm3ZeaCzFxE8+fiscyckf/KfD8y80fAvog4v5SWAS90cUrd9CqwNCLOKL8zy5ihNxSc0O9EP978uJT3+ATwOWBnRPyg1P6ifCKAdDNwX/nH1l7gxi7Ppysyc0dEbAaeoXnn4rPM0Hek+050SVIVT2FJkqoYIJKkKgaIJKmKASJJqmKASJKqGCCSpCoGiCSpigEiSary/wEgIuNi0FSBEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_train_df = train_df.groupby('grouped_ship_count')\n",
    "grouped_train_df['ships'].hist(bins=np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ships_for_validation(in_df, total, valid_pct):\n",
    "    group_cnt = in_df['ImageId'].count()\n",
    "    frac = int(total * valid_pct * group_cnt // total)\n",
    "    print(\"group cnt: {}, fraction: {}\".format(group_cnt, frac))\n",
    "    return in_df.sample(frac, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group cnt: 2060931, fraction: 2060\n",
      "group cnt: 687335, fraction: 687\n",
      "group cnt: 339823, fraction: 339\n",
      "group cnt: 235069, fraction: 235\n",
      "group cnt: 142524, fraction: 142\n",
      "group cnt: 93124, fraction: 93\n",
      "group cnt: 58065, fraction: 58\n"
     ]
    }
   ],
   "source": [
    "total = train_df['ImageId'].count()\n",
    "valid_df = grouped_train_df.apply(sample_ships_for_validation, total, VALIDATION_COUNT_PCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df = train_df[~train_df['ImageId'].isin(valid_df['ImageId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 3605011, validation sample size: 3614\n"
     ]
    }
   ],
   "source": [
    "print(\"training samples: {}, validation sample size: {}\".format(all_train_df['ImageId'].count(), valid_df['ImageId'].count()))\n",
    "training_samples = all_train_df['ImageId'].count()\n",
    "validation_samples = valid_df['ImageId'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = make_image_gen(all_train_df)\n",
    "# train_x, train_y = next(train_gen)\n",
    "# print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "# print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (3614, 768, 768, 3) 0.0 1.0\n",
      "y (3614, 768, 768, 1) 0 1\n"
     ]
    }
   ],
   "source": [
    "valid_gen = make_image_gen(valid_df, validation_samples) # pull all validation samples\n",
    "valid_x, valid_y = next(valid_gen)\n",
    "print('x', valid_x.shape, valid_x.min(), valid_x.max())\n",
    "print('y', valid_y.shape, valid_y.min(), valid_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to CSV and \n",
    "masks[masks['ImageId'].isin(all_train_df['ImageId'])].to_csv('{}/train_ship_segmentations_train.csv.0'.format(ship_dir), index=False)\n",
    "masks[masks['ImageId'].isin(valid_df['ImageId'])].to_csv('{}/train_ship_segmentations_valid.csv.0'.format(ship_dir), index=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
